import OpenAI from 'openai';

export interface MensagemIA {
  role: 'system' | 'user' | 'assistant';
  content: string;
  name?: string;
}

export interface ConfiguracaoIA {
  apiKey: string;
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export interface RespostaIA {
  conteudo: string;
  tokens: number;
  modelo: string;
  tempo: number;
}

/**
 * Servi√ßo para integra√ß√£o com OpenAI GPT
 */
export class OpenAIService {
  private static instance: OpenAIService;
  private client: OpenAI | null = null;
  private configuracao: ConfiguracaoIA | null = null;

  private constructor() {}

  /**
   * Singleton pattern
   */
  static getInstance(): OpenAIService {
    if (!OpenAIService.instance) {
      OpenAIService.instance = new OpenAIService();
      // Auto-configurar se a API key estiver no .env
      OpenAIService.instance.autoConfigurar();
    }
    return OpenAIService.instance;
  }

  /**
   * Auto-configura usando vari√°veis de ambiente se dispon√≠veis
   */
  private autoConfigurar(): void {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    const model = import.meta.env.VITE_OPENAI_MODEL;
    const organization = import.meta.env.VITE_OPENAI_ORGANIZATION;

    if (apiKey) {
      console.log('ü§ñ API Key encontrada no .env - configurando OpenAI automaticamente');
      this.configurar({
        apiKey,
        model: model || 'gpt-4o-mini',
        temperature: 0.7,
        maxTokens: 1000,
      });

      if (organization) {
        // Se houver organiza√ß√£o, reconfigurar o cliente com ela
        this.client = new OpenAI({
          apiKey,
          organization,
          dangerouslyAllowBrowser: true,
        });
      }
    }
  }

  /**
   * Configura a API da OpenAI
   */
  configurar(config: ConfiguracaoIA): void {
    this.configuracao = {
      model: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 1000,
      ...config,
    };

    this.client = new OpenAI({
      apiKey: config.apiKey,
      dangerouslyAllowBrowser: true, // Permitir uso no browser
    });
  }

  /**
   * Verifica se est√° configurado
   */
  estaConfigurado(): boolean {
    return this.client !== null && this.configuracao !== null;
  }

  /**
   * Envia mensagem para a IA
   */
  async enviarMensagem(mensagens: MensagemIA[]): Promise<RespostaIA> {
    if (!this.client || !this.configuracao) {
      throw new Error('OpenAI n√£o est√° configurado');
    }

    const inicioTempo = Date.now();

    try {
      const parametros: Record<string, unknown> = {
        model: this.configuracao.model!,
        messages: mensagens,
      };

      if (this.configuracao.temperature !== undefined) {
        parametros.temperature = this.configuracao.temperature;
      }

      if (this.configuracao.maxTokens !== undefined) {
        parametros.max_tokens = this.configuracao.maxTokens;
      }

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const resposta = await this.client.chat.completions.create(parametros as any);

      const tempoDecorrido = Date.now() - inicioTempo;

      const conteudo = resposta.choices[0]?.message?.content || '';
      const tokens = resposta.usage?.total_tokens || 0;

      return {
        conteudo,
        tokens,
        modelo: this.configuracao.model!,
        tempo: tempoDecorrido,
      };
    } catch (error) {
      console.error('Erro ao chamar OpenAI:', error);
      throw new Error(
        `Falha na comunica√ß√£o com OpenAI: ${error instanceof Error ? error.message : 'Erro desconhecido'}`,
      );
    }
  }

  /**
   * Gera resposta de personagem IA
   */
  async gerarRespostaPersonagem(
    contexto: string,
    personalidade: string,
    situacao: string,
    historico: string[],
  ): Promise<RespostaIA> {
    const prompt = this.construirPromptPersonagem(contexto, personalidade, situacao, historico);

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: situacao,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Gera narra√ß√£o do mestre
   */
  async gerarNarracao(contexto: string, acoes: string[], ambiente: string): Promise<RespostaIA> {
    const prompt = this.construirPromptMestre(contexto, ambiente);

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: `A√ß√µes dos jogadores: ${acoes.join(', ')}`,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Analisa a√ß√£o de combate
   */
  async analisarAcaoCombate(
    acao: string,
    personagem: string,
    contexto: string,
  ): Promise<RespostaIA> {
    const prompt = `Voc√™ √© um mestre de RPG D&D 5e. Analise a seguinte a√ß√£o de combate e determine o resultado.

REGRAS:
- Seja preciso com as mec√¢nicas do D&D 5e
- Descreva o resultado de forma cinematogr√°fica
- Indique qual dado rolar se necess√°rio
- Considere modificadores relevantes

PERSONAGEM: ${personagem}
CONTEXTO: ${contexto}
A√á√ÉO: ${acao}

Responda no formato:
RESULTADO: [sucesso/falha/necessita_rolagem]
DESCRI√á√ÉO: [descri√ß√£o narrativa]
DADOS: [dados a rolar, se necess√°rio]
EFEITOS: [efeitos mec√¢nicos]`;

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Gera sugest√µes de a√ß√£o
   */
  async sugerirAcoes(
    personagem: string,
    situacao: string,
    habilidades: string[],
  ): Promise<RespostaIA> {
    const prompt = `Voc√™ √© um assistente de RPG. Sugira 3-5 a√ß√µes poss√≠veis para o personagem na situa√ß√£o atual.

PERSONAGEM: ${personagem}
SITUA√á√ÉO: ${situacao}
HABILIDADES DISPON√çVEIS: ${habilidades.join(', ')}

Sugira a√ß√µes variadas: combate, sociais, utilit√°rias, criativas.
Seja conciso e espec√≠fico.`;

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Constr√≥i prompt para personagem
   */
  private construirPromptPersonagem(
    contexto: string,
    personalidade: string,
    situacao: string,
    historico: string[],
  ): string {
    return `Voc√™ est√° interpretando um personagem de RPG com a seguinte personalidade:

${personalidade}

CONTEXTO ATUAL: ${contexto}

HIST√ìRICO RECENTE:
${historico.slice(-5).join('\n')}

INSTRU√á√ïES:
- Mantenha-se fiel √† personalidade do personagem
- Responda em primeira pessoa
- Seja coerente com o contexto e hist√≥rico
- Limite a 2-3 par√°grafos
- Inclua di√°logo e/ou a√ß√µes quando apropriado

SITUA√á√ÉO ATUAL: ${situacao}

Responda como o personagem reagiria:`;
  }

  /**
   * Constr√≥i prompt para mestre
   */
  private construirPromptMestre(contexto: string, ambiente: string): string {
    return `Voc√™ √© um Mestre de RPG experiente narrando uma aventura.

CONTEXTO: ${contexto}
AMBIENTE: ${ambiente}

INSTRU√á√ïES:
- Seja descritivo e envolvente
- Mantenha o ritmo da hist√≥ria
- Introduza elementos interessantes
- Responda √†s a√ß√µes dos jogadores
- Use tom adequado ao ambiente
- Limite a 2-3 par√°grafos

Narre o que acontece a seguir:`;
  }

  /**
   * Testa conex√£o com a API
   */
  async testarConexao(): Promise<boolean> {
    if (!this.client) {
      return false;
    }

    try {
      const resposta = await this.client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'Teste de conex√£o.' }],
        max_tokens: 10,
      });

      return resposta.choices.length > 0;
    } catch {
      return false;
    }
  }

  /**
   * Obt√©m modelos dispon√≠veis
   */
  getModelosDisponiveis(): string[] {
    return ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-32k', 'gpt-4-turbo-preview'];
  }

  /**
   * Estima custo de uma opera√ß√£o
   */
  estimarCusto(tokens: number, modelo: string = 'gpt-3.5-turbo'): number {
    // Pre√ßos aproximados por 1000 tokens (valores de exemplo)
    const precos: Record<string, number> = {
      'gpt-3.5-turbo': 0.002,
      'gpt-3.5-turbo-16k': 0.003,
      'gpt-4': 0.03,
      'gpt-4-32k': 0.06,
      'gpt-4-turbo-preview': 0.01,
    };

    const precoPor1000 = precos[modelo] || precos['gpt-3.5-turbo']!;
    return (tokens / 1000) * precoPor1000;
  }

  /**
   * Obt√©m estat√≠sticas de uso
   */
  getEstatisticas(): {
    totalChamadas: number;
    totalTokens: number;
    custoEstimado: number;
    modeloMaisUsado: string;
  } {
    // Em uma implementa√ß√£o real, isso seria persistido
    return {
      totalChamadas: 0,
      totalTokens: 0,
      custoEstimado: 0,
      modeloMaisUsado: 'gpt-3.5-turbo',
    };
  }

  /**
   * Limpa configura√ß√£o
   */
  limparConfiguracao(): void {
    this.client = null;
    this.configuracao = null;
  }
}
