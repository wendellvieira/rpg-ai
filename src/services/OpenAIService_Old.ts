import OpenAI from 'openai';

export interface MensagemIA {
  role: 'system' | 'user' | 'assistant';
  content: string;
  name?: string;
}

export interface ConfiguracaoIA {
  apiKey: string;
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export interface RespostaIA {
  conteudo: string;
  tokens: number;
  modelo: string;
  tempo: number;
}

/**
 * Limpa formata√ß√£o markdown de respostas JSON da IA
 */
export function limparRespostaJSON(resposta: string): string {
  let conteudoLimpo = resposta.trim();

  // Remover blocos de c√≥digo markdown
  if (conteudoLimpo.startsWith('```json')) {
    conteudoLimpo = conteudoLimpo.replace(/^```json\s*/, '').replace(/\s*```\s*$/, '');
  } else if (conteudoLimpo.startsWith('```')) {
    conteudoLimpo = conteudoLimpo.replace(/^```\s*/, '').replace(/\s*```\s*$/, '');
  }

  return conteudoLimpo.trim();
}

/**
 * Servi√ßo para integra√ß√£o com OpenAI GPT
 */
export class OpenAIService {
  private static instance: OpenAIService;
  private client: OpenAI | null = null;
  private configuracao: ConfiguracaoIA | null = null;

  private constructor() {}

  /**
   * Singleton pattern
   */
  static getInstance(): OpenAIService {
    if (!OpenAIService.instance) {
      OpenAIService.instance = new OpenAIService();
      // Auto-configurar se a API key estiver no .env
      OpenAIService.instance.autoConfigurar();
    }
    return OpenAIService.instance;
  }

  /**
   * Auto-configura usando vari√°veis de ambiente se dispon√≠veis
   */
  private autoConfigurar(): void {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    const model = import.meta.env.VITE_OPENAI_MODEL;
    const organization = import.meta.env.VITE_OPENAI_ORGANIZATION;

    console.log('ü§ñ [DEBUG] AutoConfigurar - API Key encontrada:', !!apiKey);
    console.log('ü§ñ [DEBUG] AutoConfigurar - Model:', model || 'padr√£o');
    console.log('ü§ñ [DEBUG] AutoConfigurar - Organization:', organization || 'nenhuma');

    if (apiKey) {
      console.log('ü§ñ [DEBUG] API Key encontrada no .env - configurando OpenAI automaticamente');
      this.configurar({
        apiKey,
        model: model || 'gpt-4o-mini',
        temperature: 0.7,
        maxTokens: 1000,
      });

      if (organization) {
        console.log('ü§ñ [DEBUG] Configurando organiza√ß√£o:', organization);
        // Se houver organiza√ß√£o, reconfigurar o cliente com ela
        this.client = new OpenAI({
          apiKey,
          organization,
          dangerouslyAllowBrowser: true,
        });
      }

      console.log(
        'ü§ñ [DEBUG] OpenAI configurado via .env - estaConfigurado:',
        this.estaConfigurado(),
      );
    } else {
      console.log('ü§ñ [DEBUG] Nenhuma API Key encontrada no .env');
    }
  }

  /**
   * Configura a API da OpenAI
   */
  configurar(config: ConfiguracaoIA): void {
    console.log('ü§ñ [DEBUG] Configurando OpenAI com:', {
      hasApiKey: !!config.apiKey,
      model: config.model,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
    });

    this.configuracao = {
      model: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 1000,
      ...config,
    };

    this.client = new OpenAI({
      apiKey: config.apiKey,
      dangerouslyAllowBrowser: true, // Permitir uso no browser
    });

    console.log('ü§ñ [DEBUG] OpenAI configurado - cliente criado:', !!this.client);
    console.log('ü§ñ [DEBUG] OpenAI configurado - estaConfigurado:', this.estaConfigurado());
  }

  /**
   * Verifica se est√° configurado
   */
  estaConfigurado(): boolean {
    return this.client !== null && this.configuracao !== null;
  }

  /**
   * Envia mensagem para a IA
   */
  async enviarMensagem(mensagens: MensagemIA[]): Promise<RespostaIA> {
    console.log('ü§ñ [DEBUG] enviarMensagem - Verificando configura√ß√£o...');
    console.log('ü§ñ [DEBUG] enviarMensagem - Cliente existe:', !!this.client);
    console.log('ü§ñ [DEBUG] enviarMensagem - Configura√ß√£o existe:', !!this.configuracao);

    if (!this.client || !this.configuracao) {
      const erro = 'OpenAI n√£o est√° configurado';
      console.error('ü§ñ [ERROR]', erro);
      throw new Error(erro);
    }

    const inicioTempo = Date.now();
    console.log('ü§ñ [DEBUG] enviarMensagem - Iniciando chamada para OpenAI...');

    try {
      const parametros: Record<string, unknown> = {
        model: this.configuracao.model!,
        messages: mensagens,
      };

      if (this.configuracao.temperature !== undefined) {
        parametros.temperature = this.configuracao.temperature;
      }

      if (this.configuracao.maxTokens !== undefined) {
        parametros.max_tokens = this.configuracao.maxTokens;
      }

      console.log('ü§ñ [DEBUG] enviarMensagem - Par√¢metros:', {
        model: parametros.model,
        temperature: parametros.temperature,
        max_tokens: parametros.max_tokens,
        mensagens: mensagens.length,
      });

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const resposta = await this.client.chat.completions.create(parametros as any);

      const tempoDecorrido = Date.now() - inicioTempo;
      console.log('ü§ñ [DEBUG] enviarMensagem - Resposta recebida em', tempoDecorrido, 'ms');

      const conteudo = resposta.choices[0]?.message?.content || '';
      const tokens = resposta.usage?.total_tokens || 0;

      const resultado = {
        conteudo,
        tokens,
        modelo: this.configuracao.model!,
        tempo: tempoDecorrido,
      };

      console.log('ü§ñ [DEBUG] enviarMensagem - Resultado final:', {
        conteudo: conteudo.substring(0, 100) + '...',
        tokens,
        modelo: resultado.modelo,
        tempo: resultado.tempo,
      });

      return resultado;
    } catch (error) {
      console.error('ü§ñ [ERROR] Erro ao chamar OpenAI:', error);
      console.error('ü§ñ [ERROR] Tipo do erro:', typeof error);
      console.error('ü§ñ [ERROR] Stack trace:', error instanceof Error ? error.stack : 'N/A');

      const mensagemErro = error instanceof Error ? error.message : 'Erro desconhecido';
      console.error('ü§ñ [ERROR] Mensagem final:', mensagemErro);

      throw new Error(`Falha na comunica√ß√£o com OpenAI: ${mensagemErro}`);
    }
  }

  /**
   * Gera resposta de personagem IA
   */
  async gerarRespostaPersonagem(
    contexto: string,
    personalidade: string,
    situacao: string,
    historico: string[],
  ): Promise<RespostaIA> {
    const prompt = this.construirPromptPersonagem(contexto, personalidade, situacao, historico);

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: situacao,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Gera narra√ß√£o do mestre
   */
  async gerarNarracao(contexto: string, acoes: string[], ambiente: string): Promise<RespostaIA> {
    const prompt = this.construirPromptMestre(contexto, ambiente);

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
      {
        role: 'user',
        content: `A√ß√µes dos jogadores: ${acoes.join(', ')}`,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Analisa a√ß√£o de combate
   */
  async analisarAcaoCombate(
    acao: string,
    personagem: string,
    contexto: string,
  ): Promise<RespostaIA> {
    const prompt = `Voc√™ √© um mestre de RPG D&D 5e. Analise a seguinte a√ß√£o de combate e determine o resultado.

REGRAS:
- Seja preciso com as mec√¢nicas do D&D 5e
- Descreva o resultado de forma cinematogr√°fica
- Indique qual dado rolar se necess√°rio
- Considere modificadores relevantes

PERSONAGEM: ${personagem}
CONTEXTO: ${contexto}
A√á√ÉO: ${acao}

Responda no formato:
RESULTADO: [sucesso/falha/necessita_rolagem]
DESCRI√á√ÉO: [descri√ß√£o narrativa]
DADOS: [dados a rolar, se necess√°rio]
EFEITOS: [efeitos mec√¢nicos]`;

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Gera sugest√µes de a√ß√£o
   */
  async sugerirAcoes(
    personagem: string,
    situacao: string,
    habilidades: string[],
  ): Promise<RespostaIA> {
    const prompt = `Voc√™ √© um assistente de RPG. Sugira 3-5 a√ß√µes poss√≠veis para o personagem na situa√ß√£o atual.

PERSONAGEM: ${personagem}
SITUA√á√ÉO: ${situacao}
HABILIDADES DISPON√çVEIS: ${habilidades.join(', ')}

Sugira a√ß√µes variadas: combate, sociais, utilit√°rias, criativas.
Seja conciso e espec√≠fico.`;

    const mensagens: MensagemIA[] = [
      {
        role: 'system',
        content: prompt,
      },
    ];

    return await this.enviarMensagem(mensagens);
  }

  /**
   * Constr√≥i prompt para personagem
   */
  private construirPromptPersonagem(
    contexto: string,
    personalidade: string,
    situacao: string,
    historico: string[],
  ): string {
    return `Voc√™ est√° interpretando um personagem de RPG com a seguinte personalidade:

${personalidade}

CONTEXTO ATUAL: ${contexto}

HIST√ìRICO RECENTE:
${historico.slice(-5).join('\n')}

INSTRU√á√ïES:
- Mantenha-se fiel √† personalidade do personagem
- Responda em primeira pessoa
- Seja coerente com o contexto e hist√≥rico
- Limite a 2-3 par√°grafos
- Inclua di√°logo e/ou a√ß√µes quando apropriado

SITUA√á√ÉO ATUAL: ${situacao}

Responda como o personagem reagiria:`;
  }

  /**
   * Constr√≥i prompt para mestre
   */
  private construirPromptMestre(contexto: string, ambiente: string): string {
    return `Voc√™ √© um Mestre de RPG experiente narrando uma aventura.

CONTEXTO: ${contexto}
AMBIENTE: ${ambiente}

INSTRU√á√ïES:
- Seja descritivo e envolvente
- Mantenha o ritmo da hist√≥ria
- Introduza elementos interessantes
- Responda √†s a√ß√µes dos jogadores
- Use tom adequado ao ambiente
- Limite a 2-3 par√°grafos

Narre o que acontece a seguir:`;
  }

  /**
   * Testa conex√£o com a API
   */
  async testarConexao(): Promise<boolean> {
    if (!this.client) {
      return false;
    }

    try {
      const resposta = await this.client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'Teste de conex√£o.' }],
        max_tokens: 10,
      });

      return resposta.choices.length > 0;
    } catch {
      return false;
    }
  }

  /**
   * Obt√©m modelos dispon√≠veis
   */
  getModelosDisponiveis(): string[] {
    return ['gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-4', 'gpt-4-32k', 'gpt-4-turbo-preview'];
  }

  /**
   * Estima custo de uma opera√ß√£o
   */
  estimarCusto(tokens: number, modelo: string = 'gpt-3.5-turbo'): number {
    // Pre√ßos aproximados por 1000 tokens (valores de exemplo)
    const precos: Record<string, number> = {
      'gpt-3.5-turbo': 0.002,
      'gpt-3.5-turbo-16k': 0.003,
      'gpt-4': 0.03,
      'gpt-4-32k': 0.06,
      'gpt-4-turbo-preview': 0.01,
    };

    const precoPor1000 = precos[modelo] || precos['gpt-3.5-turbo']!;
    return (tokens / 1000) * precoPor1000;
  }

  /**
   * Obt√©m estat√≠sticas de uso
   */
  getEstatisticas(): {
    totalChamadas: number;
    totalTokens: number;
    custoEstimado: number;
    modeloMaisUsado: string;
  } {
    // Em uma implementa√ß√£o real, isso seria persistido
    return {
      totalChamadas: 0,
      totalTokens: 0,
      custoEstimado: 0,
      modeloMaisUsado: 'gpt-3.5-turbo',
    };
  }

  /**
   * Limpa configura√ß√£o
   */
  limparConfiguracao(): void {
    this.client = null;
    this.configuracao = null;
  }
}
